\documentclass[fleqn,10pt]{wlpeerj}
%% DE created stub file June 30, 2014 initially set up for PeerJ
%% Have at - change whatever you like.
%% Text is being tracked using Mercurial for revision control.  

% some packages here 
\usepackage{graphicx}
\usepackage{siunitx}
\usepackage[hidelinks]{hyperref}
\usepackage{lineno} % for review only

% define some things here
\newcommand{\argus}{\texttt{argus}}
\newcommand{\detectpatterns}{\texttt{argus\_detect\_patterns}}
\newcommand{\simplified}{\texttt{argus\_simplified}}
\newcommand{\pipcommand}{\texttt{sudo pip install argus}}
\newcommand{\argusrepo}{\url{ssh://hg@bitbucket.org/devangel77b/argus}}
\newcommand{\matlabtoolbox}{add link here}

\title{Fun things you can do with a bunch of GoPros}

\author[1,2]{Brandon Jackson \thanks{author for correspondence: brandon.e.jackson@gmail.com}}
\author[2]{Dennis Evangelista}
\author[2]{Ty Hedrick}
\affil[1]{Longwood College, Charlottesville, VA}
\affil[2]{University of North Carolina at Chapel Hill, NC 27599-3280, USA}

\keywords{videography, photogrammetry, kinematics, multiple cameras, calibration}

\begin{abstract}
Ecological, behavioral, and biomechanical studies often need to quantify movement and behavior in three dimensions.  In laboratory studies, a major tool to accomplish these is the use of multiple, calibrated high-speed cameras.  Until very recently, complexity, weight and cost of such cameras has made their deployment in field situations risky; furthermore such cameras are often not affordable for early career researchers, teaching use by undergraduates, or for those not in biomechanics who don't have an overriding primary need for such toys.  Here we describe a solution and tool set using multiple inexpensive cameras to bridge such needs.  The availability of lower cost, portable and rugged solutions (and the likely future ubiquity of inexpensive cameras of reasonable performance) has promise to open up new areas of biological study by providing precise, 3D tracking and quantification of movement to more researchers. 
\end{abstract}

\begin{document}

\flushbottom
\maketitle
\thispagestyle{empty}

%% for line numbers
%\setpagewiselinenumbers
\modulolinenumbers[5]
\linenumbers

\section*{Introduction}

Introduction here. Citations here \citep{Theriault:2014, Bradski:2008}. 

3D reconstruction of position is an important technique that can be used to quantitatively study (STUFF).  For example (STUFF, Citations). As cameras become more capable, lightweight, and affordable, such techniques are increasingly attractive for use in teaching or in field situations.  

Calibration of multiple cameras and using them to reconstruct position can be nontrival.  To use multiple cameras to reconstruct 3D positions requires knowledge of the cameras' intrinsic parameters, such as focal length, principal point, and distortion coefficients.  It also requires knowledge of the extrinsic parameters: the relative positions and orientations of the cameras with respect to one another. Finally, 3D reconstruction generally requires knowing that the frames are synchronized in time.  While a number of tools exist to actually perform the calibration (Borguet, Theriault et al) they can still be daunting to general users.

In this paper, we provide a simple work flow and tools aimed specifically at low cost 3D reconstruction using multiple consumer-grade cameras (specifically, the GoPro Hero 3 series; although we have used the techniques here with Flip MinoHD and various models of digital SLR cameras).  To ease adoption of such techniques, we provide a database of calibrations; simple tools for obtaining the intrinsics from printed patterns; and methods for obtaining audio synchronization, wand tracking (and keypoint detection?) used to obtain extrinsics in the field. Our goal in this paper is simplify the employment of 3D reconstruction techniques so that they may be used in ecological field studies, undergraduate teaching of biomechanics, etc etc etc. 

\subsection*{How does 3D reconstruction work in a nutshell?}
\subsection*{Ecologist-proof roadmap of how to set up to do it}

\section*{Methods and materials}
\subsection*{Cameras}
We demonstrate these methods using GoPro Hero3 Black cameras (GoPro, Santa Cruz, CA), mounted in stock cases (serial numbers), as well as Nikon D300S DSLR with 24 mm lenses. 

\subsection*{Software tools}
Several software tools exist for providing camera calibrations, including (citations).  Here we present a simplified set of tools optimized for ease of use: the Python \argus\ package (\argusrepo, or install using \pipcommand) and the Matlab (NAME) toolbox (\matlabtoolbox). 

\subsection*{Laboratory calibration of camera intrinsics}
An online library of camera intrinsic parameters is provided (HERE).  The Python \argus\ package can be used to obtain a laboratory calibration for camera intrinsics, as a check or for a configuration not provided. First, a test pattern (LINK) is printed and firmly affixed to a flat surface; we typically use either a (dimensions) chessboard pattern or a (dimensions) dot pattern (see Figure X).  The camera is set for the desired resolution, frame rate, and field of view and the patterns are filmed; the use of an external monitor can aid the process.  

The resulting video is analyzed frame by frame to locate the patterns, using the \detectpatterns\ script.  The detected patterns are used to iteratively find a set of intrinsic parameters that minimizes the root mean squared error (rmse) of the projection; this is accomplished with the \simplified\ script.  We have configured the \simplified\ script to work for most typical applications; additional scripts are provided in \argus\ to provide fine control over the order of parameter optimization and the detailed stage-by-stage minimization search.

Move to results: As an example of a calibration, we filmed a (dimensions) pattern using a GoPro Hero3 Black camera (figure X).  The resulting calibration data is given in Table X. To examine the spread in calibration values, we repeated the calibration 2000 times using 30 patterns for each replicate. The best rmse value falls within the 25th-75th interquartile range and is near the median value for the best 200 calibrations, suggesting we are not in a local minimum and that the calibration parameters are significant...   

\begin{figure}
\caption{(a) Example video frame for laboratory calibration of GoPro Hero3 Black camera intrinsics showing (dimensions) pattern.  (b) Pattern detected using the \detectpatterns\ script.}
\label{fig:labcal1}
\end{figure}

\begin{table}
\caption{Results of laboratory calibration of GoPro Hero3 Black camera intrinsics using 1000 replicates, showing best rmse and the median, 25th and 75th percentile values of the top 100 solutions. }
\label{tab:labcal2}
\begin{center}
\begin{tabular}{lcccc}
parameter & best & 25\% & median & 75\% \\
\cline{1-5}
focal length $f$, pixels & & & &\\
principal point $c_x$, pixels & & & & \\
principal point $c_y$, pixels & & & & \\
aspect ratio $AR$ & 1 & 1 & 1 & 1\\
skew $s$ & 0 & 0 & 0 & 0 \\
radial $k_1$ & & & & \\
radial $k_2$ & & & & \\
tangential $t_1$ & 0 & 0 & 0 & 0 \\
tangential $t_2$ & 0 & 0 & 0 & 0 \\
radial $k_3$ & & & & \\
\end{tabular}
\end{center}
\end{table}


\subsection*{Field deployment and field calibration of camera extrinsics}
\subsection*{3D reconstruction}

\section*{Results and discussion}
\subsection*{Simple lab example}
\subsection*{Simple field example}

\section*{Acknowledgements}
Thank you everyone.

\bibliography{gopro}
\end{document}